{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Sesgos: </h2>\n",
    "\n",
    "[AI and Algorithmic Bias: Source, Detection, Mitigation and Implications](https://deliverypdf.ssrn.com/delivery.php?ID=394013103113028031116028106115064109050063050068079069007115005009071021107023120009034102098026110059062007088117094005007070045007060077040005025104085120113110024020033120001086005011027007082006084093103115074075007006022066013116006071003016067&EXT=pdf&INDEX=TRUE)\n",
    "\n",
    "El artículo \"AI and Algorithmic Bias: Source, Detection, Mitigation and Implications\" de Runshan Fu y colaboradores analiza cómo la inteligencia artificial y los algoritmos de aprendizaje automático, usados ampliamente en la toma de decisiones, han mostrado tendencias crecientes a perpetuar sesgos y desigualdades estructurales. Aborda la definición del sesgo algorítmico, los retos en su detección, las fuentes de este sesgo y revisa métodos para su corrección. Finalmente, el artículo discute cómo los algoritmos no sesgados pueden conducir a resultados sociales sesgados, concluyendo con preguntas abiertas y direcciones para futuras investigaciones.\n",
    "\n",
    "El artículo utiliza diversos métodos para abordar el sesgo algorítmico, incluyendo la pre-procesamiento de datos para eliminar sesgos antes del entrenamiento del algoritmo, la incorporación de restricciones de equidad durante el entrenamiento, y el post-procesamiento de las predicciones para corregir sesgos en los resultados. También se analizan métodos estadísticos y econométricos para la detección de sesgos, considerando la respuesta estratégica de los agentes a los algoritmos. Estos enfoques buscan equilibrar la precisión de las predicciones con consideraciones de equidad y justicia.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "[AI has a racism problem, but fixing it is complicated, say experts](https://www.cbc.ca/news/science/artificial-intelligence-racism-bias-1.6027150)\n",
    "\n",
    "El artículo de CBC News aborda el problema del racismo en la inteligencia artificial, destacando varios casos donde programas de IA han producido resultados racistas y sesgados. Ejemplos incluyen el uso de términos racistas en descripciones de productos en Amazon y traducciones sesgadas en Baidu. Expertos en IA explican que estos problemas surgen de cómo los algoritmos procesan grandes cantidades de datos de internet, que a menudo incluyen estereotipos y prejuicios. La solución al problema es complicada, ya que filtrar los datos para eliminar palabras y estereotipos racistas también podría censurar textos históricos y culturales relevantes. La discusión se centra en si los programas de IA deberían aprender por sí mismos o necesitar intervención humana para contrarrestar los sesgos.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "[Racism And AI: Here’s How It’s Been Criticized For Amplifying Bias](https://www.forbes.com/sites/ariannajohnson/2023/05/25/racism-and-ai-heres-how-its-been-criticized-for-amplifying-bias/?sh=38a50fc9269d)\n",
    "\n",
    "El artículo destaca el problema del racismo en la inteligencia artificial, mostrando cómo esta puede perpetuar sesgos raciales en áreas como la salud, la aplicación de la ley y la tecnología. Se mencionan ejemplos de IA que no reconocen adecuadamente rostros de personas negras y cómo ciertas aplicaciones de reconocimiento facial han demostrado ser sesgadas. Se discute cómo la IA, alimentada por datos con prejuicios existentes, puede producir resultados sesgados y se plantea el debate sobre cómo abordar estos problemas. La necesidad de una mayor diversidad en los datos de entrenamiento de la IA y la intervención humana para corregir sesgos se subraya como crucial.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "[Sharing learnings about our image cropping algorithm](https://blog.twitter.com/engineering/en_us/topics/insights/2021/sharing-learnings-about-our-image-cropping-algorithm)\n",
    "\n",
    "Twitter recibió comentarios sobre su algoritmo de recorte de imágenes y su posible sesgo. La empresa realizó un análisis en colaboración con su equipo META y el equipo de investigación de contenido. Se evaluó el algoritmo para sesgos de género y raza y su alineación con el objetivo de permitir elecciones autónomas en la plataforma. Se encontraron diferencias en el recorte de imágenes basadas en género y raza, aunque no se evidenció sesgo de objetivación. Twitter decidió que la mejor solución es permitir a los usuarios controlar cómo se muestran sus imágenes, eliminando el recorte automático. La empresa está comprometida con la transparencia y la responsabilidad en el uso de sistemas de decisión algorítmica como el aprendizaje automático.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "[A.I. Bias Caused 80% Of Black Mortgage Applicants To Be Denied](https://www.forbes.com/sites/korihale/2021/09/02/ai-bias-caused-80-of-black-mortgage-applicants-to-be-denied/?sh=6da4e5aa36fe)\n",
    "\n",
    "Una investigación de The Markup reveló que los prestamistas son más propensos a rechazar solicitudes de préstamos hipotecarios a personas de color en comparación con solicitantes blancos de características financieras similares. El análisis señala que la IA en la originación de préstamos podría estar contribuyendo a estas disparidades. Se observó que el uso de software en las decisiones de préstamos hipotecarios, a menudo dictado por agencias gubernamentales, podría estar afectando negativamente la tasa de propiedad de viviendas entre afroamericanos. Las asociaciones bancarias han criticado este análisis, resaltando la complejidad de los detalles algorítmicos y las tendencias históricas en la propiedad de viviendas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Responsabilidad algorítmica</h2>\n",
    "\n",
    "[Roboleyes: Principios de responsabilidad algorítmica en la Inteligencia Artificial](https://mitsloanreview.mx/colaborador/roboleyes-principios-de-responsabilidad-algoritmica-en-la-inteligencia-artificial/)\n",
    "\n",
    "Aborda la importancia de la responsabilidad en el uso de algoritmos en la inteligencia artificial. Discute cómo se deben desarrollar y utilizar estas herramientas tecnológicas para garantizar que sirvan al bienestar humano y no lo contrario. El artículo subraya la necesidad de principios como la seguridad en los sistemas, la gobernanza de datos, la transparencia, la equidad, y la supervisión humana. Estos principios son fundamentales para asegurar que la IA se desarrolle y se aplique de manera ética y responsable, evitando sesgos y discriminación.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "En el artículo de Roboleyes hacen mención de algunos recursos interesantes:\n",
    "[Propuesta de Reglamento por el que se establecen normas armonizadas en materia de inteligencia artificial](https://digital-strategy.ec.europa.eu/es/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence)\n",
    "y\n",
    "[Blueprint for an AI Bill of Rights: MAKING AUTOMATED SYSTEMS WORK FOR THE AMERICAN PEOPLE](https://www.whitehouse.gov/ostp/ai-bill-of-rights/)\n",
    "\n",
    "Ambos son básicamente un marco de referencia propuesto para asegurar que los sistemas automatizados funcionen en beneficio de las personas. Se centra en la promoción de prácticas éticas y responsables en el desarrollo y uso de la inteligencia artificial, priorizando los derechos y el bienestar de los individuos. Este documento propone directrices y principios para guiar la implementación de sistemas de IA, asegurando que sean seguros, transparentes, justos y que operen bajo supervisión humana adecuada para evitar sesgos y discriminación.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importancia de la ética</h2>\n",
    "\n",
    "La ética en la inteligencia artificial es crucial para asegurar que la tecnología se desarrolle y utilice de manera que beneficie a la sociedad y no cause daño. Esto incluye abordar problemas como el sesgo y la discriminación, garantizar la privacidad y seguridad de los datos, y considerar las implicaciones morales de las decisiones automatizadas. La ética en la IA también implica la responsabilidad y la transparencia en el diseño y la implementación de sistemas de IA, asegurando que estos sistemas sean justos, confiables y respeten los derechos humanos y las libertades fundamentales."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
